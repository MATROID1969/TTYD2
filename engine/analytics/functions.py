#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# =============================================================
# Survivor f√ºggv√©nyek (v√°ltozatlan logika)
# =============================================================

import pandas as pd
import numpy as np
import unicodedata
import re
from difflib import SequenceMatcher
from typing import Iterable, Optional, List



def calc_survivor(df_filtered: pd.DataFrame, vegdatum: pd.Timestamp, max_honap: int = 36):
    """
    Gyors√≠tott survivor: suffix-sum a h√≥nap hisztogramokra (O(n + H)).
    S_i = darab, ahol HONAP_KULONBSEG >= i
    A_i = darab, ahol HONAP_TELT_EL    >= i
    Survivor(i) = S_i / A_i
    """
    if df_filtered.empty:
        return pd.DataFrame({"Honap_szam": [], "Survivor": []})

    df = df_filtered.copy()

    start = pd.to_datetime(df["Szerzodeskotes_datuma"], errors="coerce")
    end = pd.to_datetime(df["Kockazatvisel√©s_vege"], errors="coerce")

    mask_valid_start = start.notna() & (start < vegdatum)
    if not mask_valid_start.any():
        return pd.DataFrame({"Honap_szam": [], "Survivor": []})

    start = start[mask_valid_start]
    end = end[mask_valid_start]

    tel = (vegdatum.year - start.dt.year) * 12 + (vegdatum.month - start.dt.month)

    min_veg_vagy_lej = end.where(end.notna() & (end < vegdatum), other=vegdatum)
    dur = (min_veg_vagy_lej.dt.year - start.dt.year) * 12 + (min_veg_vagy_lej.dt.month - start.dt.month)

    tel = tel.clip(lower=0).astype(int).to_numpy()
    dur = dur.clip(lower=0).astype(int).to_numpy()

    if tel.size == 0:
        return pd.DataFrame({"Honap_szam": [], "Survivor": []})
    H = int(min(tel.max(), max_honap))
    if H <= 0:
        return pd.DataFrame({"Honap_szam": [], "Survivor": []})

    tel_c = np.minimum(tel, H + 1)
    dur_c = np.minimum(dur, H + 1)
    bins = H + 2

    cnt_tel = np.bincount(tel_c, minlength=bins)
    cnt_dur = np.bincount(dur_c, minlength=bins)

    at_risk = np.cumsum(cnt_tel[::-1])[::-1]
    survived = np.cumsum(cnt_dur[::-1])[::-1]

    idx = np.arange(1, H + 1)
    A = at_risk[idx]
    S = survived[idx]

    with np.errstate(divide='ignore', invalid='ignore'):
        surv = np.divide(S, A, out=np.zeros_like(S, dtype=float), where=A > 0)

    return pd.DataFrame({"Honap_szam": idx, "Survivor": surv})


def expected_trapezoid(df_surv):
    """V√°rhat√≥ √©lettartam trapezoid integr√°l√°ssal (h√≥napban)"""
    if df_surv.empty or "Survivor" not in df_surv.columns:
        return 0.0
    return np.trapezoid(df_surv["Survivor"], dx=1)


def conditional_one_year_retention(df_filtered, survivor_df, vegdatum):
    """Kisz√°molja, hogy a most akt√≠v szerz≈ëd√©sek h√°ny sz√°zal√©ka lesz m√©g akt√≠v 1 √©v m√∫lva."""
    df_tmp = df_filtered.copy()

    df_tmp["Szerzodeskotes_datuma"] = pd.to_datetime(df_tmp["Szerzodeskotes_datuma"], errors="coerce")
    df_tmp["Kockazatvisel√©s_vege"] = pd.to_datetime(df_tmp["Kockazatvisel√©s_vege"], errors="coerce")

    def month_diff(start, end):
        if pd.isna(start) or pd.isna(end):
            return np.nan
        rd = relativedelta(end, start)
        return rd.years * 12 + rd.months

    df_tmp["Eltelt_honap"] = df_tmp["Szerzodeskotes_datuma"].apply(
        lambda d: month_diff(d, vegdatum)
    ).astype("Int64")

    df_tmp = df_tmp[
        (df_tmp["Kockazatvisel√©s_vege"].isna()) |
        (df_tmp["Kockazatvisel√©s_vege"] > vegdatum)
    ]

    surv_lookup = dict(zip(survivor_df["Honap_szam"], survivor_df["Survivor"]))
    cond_probs = []

    for h in df_tmp["Eltelt_honap"].dropna():
        if (h in surv_lookup) and ((h + 12) in surv_lookup):
            cond_probs.append(surv_lookup[h + 12] / surv_lookup[h])
        else:
            cond_probs.append(np.nan)

    return np.nanmean(cond_probs) * 100


def _month_diff_floor(start, end):
    """Egyszer≈± h√≥nap-k√ºl√∂nbs√©g relativedelta-val."""
    if pd.isna(start) or pd.isna(end):
        return np.nan
    rd = relativedelta(end, start)
    return rd.years * 12 + rd.months


def compute_lemor_series_by_age(df_in: pd.DataFrame, asof_date: pd.Timestamp, max_honap: int = 36):
    """
    Lemorzsol√≥d√°s (akt√≠v ar√°ny) kor-szeletek szerint az adott vizsg√°lati d√°tumra.
    """
    if df_in.empty:
        return pd.DataFrame({"Lag": [], "Aktiv_arany": []})

    df = df_in.copy()
    df["Szerzodeskotes_datuma"] = pd.to_datetime(df["Szerzodeskotes_datuma"], errors="coerce")
    df["Kockazatvisel√©s_vege"] = pd.to_datetime(df["Kockazatvisel√©s_vege"], errors="coerce")

    df = df[df["Szerzodeskotes_datuma"] <= asof_date].copy()
    if df.empty:
        return pd.DataFrame({"Lag": [], "Aktiv_arany": []})

    df["AGE"] = df["Szerzodeskotes_datuma"].apply(
        lambda d: _month_diff_floor(d, asof_date)
    ).astype("Int64")

    is_active_asof = df["Kockazatvisel√©s_vege"].isna() | (df["Kockazatvisel√©s_vege"] >= asof_date)

    rows = []
    for age in range(0, max_honap):
        mask = df["AGE"] == age
        denom = int(mask.sum())
        if denom == 0:
            continue
        num = int((is_active_asof & mask).sum())
        ratio = num / denom if denom > 0 else np.nan
        rows.append({"Lag": -(age + 1), "Aktiv_arany": ratio})

    out = pd.DataFrame(rows).sort_values("Lag")
    return out


def _normalize_and_tokenize(text: str) -> List[str]:
    """
    Normaliz√°lja √©s tokeniz√°lja a sz√∂veget:
    - kisbet≈±
    - √©kezetek elt√°vol√≠t√°sa
    - jogi form√°k elt√°vol√≠t√°sa
    - szavak list√°ja
    """
    if not isinstance(text, str):
        return []

    text = text.lower()

    # √âkezetek elt√°vol√≠t√°sa
    text = unicodedata.normalize("NFKD", text)
    text = "".join(c for c in text if not unicodedata.combining(c))

    # Jogi form√°k elt√°vol√≠t√°sa
    legal_forms = [
        r"\bkft\b", r"\bbt\b", r"\bzrt\b", r"\bnrt\b",
        r"\bkkt\b", r"\bnyrt\b", r"\bltd\b", r"\binc\b",
        r"\bco\b", r"\bcorp\b", r"\bbeteti\b", r"\btarsasag\b"
    ]
    pattern = r"(" + "|".join(legal_forms) + r")"
    text = re.sub(pattern, "", text)

    # Nem alfanumerikus karakterek sz√≥k√∂zz√©
    text = re.sub(r"[^a-z0-9]", " ", text)

    # Tokenek
    tokens = re.sub(r"\s+", " ", text).strip().split()

    return tokens


def resolve_entity(
    query_value: str,
    candidates: Iterable[str],
    max_tokens: int = 3,
    min_fuzzy_similarity: float = 0.6
) -> Optional[str]:
    """
    Entit√°sfelold√°s els≈ë sz√≥ ‚Üí els≈ë sz√≥ preferenci√°val.

    L√©p√©sek:
    1) token-alap√∫ sz≈±r√©s (1..max_tokens)
    2) ha egy marad ‚Üí vissza
    3) ha t√∂bb marad ‚Üí fuzzy d√∂nt√©s
    """

    if not query_value or not candidates:
        return None

    query_tokens = _normalize_and_tokenize(query_value)
    if not query_tokens:
        return None

    # Kandid√°tumok tokeniz√°l√°sa
    tokenized_candidates = []
    for c in candidates:
        tokens = _normalize_and_tokenize(c)
        if tokens:
            tokenized_candidates.append((c, tokens))

    if not tokenized_candidates:
        return None

    remaining = tokenized_candidates

    # 1Ô∏è‚É£‚Äì3Ô∏è‚É£ token szint≈± sz≈±r√©s
    for i in range(min(max_tokens, len(query_tokens))):
        matched = [
            (orig, tokens)
            for orig, tokens in remaining
            if len(tokens) > i and tokens[i] == query_tokens[i]
        ]

        if len(matched) == 1:
            return matched[0][0]

        if len(matched) > 1:
            remaining = matched
        else:
            break  # nincs tov√°bb sz≈±k√≠t√©s

    # Ha egy maradt
    if len(remaining) == 1:
        return remaining[0][0]

    # 4Ô∏è‚É£ Fallback: fuzzy matching
    best_candidate = None
    best_score = 0.0

    query_joined = " ".join(query_tokens)

    for orig, tokens in remaining:
        cand_joined = " ".join(tokens)
        score = SequenceMatcher(None, query_joined, cand_joined).ratio()

        if score > best_score:
            best_score = score
            best_candidate = orig

    if best_score >= min_fuzzy_similarity:
        return best_candidate

    return None


def kesedelmes_napok(
    due_in_date,
    clear_date,
    current_date=None
):
    """
    Vektoriz√°lt hat√°rid≈ë-elt√©r√©s sz√°m√≠t√°s sz√°ml√°khoz.

    Eredm√©ny (napokban):
    - negat√≠v: hat√°rid≈ë el≈ëtt fizetett
    - 0: pontosan hat√°rid≈ëre vagy hib√°s (pl. 1900-as) d√°tum
    - pozit√≠v: k√©sedelmes

    Speci√°lis szab√°ly:
    - ha az elt√©r√©s < -180 nap ‚Üí 0 (adatmin≈ës√©gi korrekci√≥)
    """

    # Biztos d√°tumkezel√©s
    due = pd.to_datetime(due_in_date, errors="coerce")
    clear = pd.to_datetime(clear_date, errors="coerce")

    # Referencia d√°tum nem fizetett sz√°ml√°khoz
    if current_date is None:
        ref = pd.Timestamp.today().normalize()
    else:
        ref = pd.to_datetime(current_date)

    # ahol nincs clear_date ‚Üí aktu√°lis d√°tum
    effective_clear = clear.fillna(ref)

    # nap elt√©r√©s
    day_diff = (effective_clear - due).dt.days

    # NaN ‚Üí 0
    day_diff = day_diff.fillna(0)

    # 1900-as / extr√©m korai d√°tumok kisz≈±r√©se
    day_diff = day_diff.where(day_diff >= -180, 0)

    return day_diff.astype(int)


def fizetesi_hossz(
    posting_date,
    due_in_date
):
    """
    Vektoriz√°lt fizet√©si hat√°rid≈ë hossz sz√°m√≠t√°s sz√°ml√°khoz.

    Eredm√©ny (napokban):
    - pozit√≠v: ennyi napos fizet√©si hat√°rid≈ë
    - 0: azonnali fizet√©s vagy hib√°s adat
    - negat√≠v eredm√©ny nem enged√©lyezett (0-ra korrig√°lva)
    """

    # Biztos d√°tumkezel√©s
    post = pd.to_datetime(posting_date, errors="coerce")
    due = pd.to_datetime(due_in_date, errors="coerce")

    # nap k√ºl√∂nbs√©g
    day_diff = (due - post).dt.days

    # NaN ‚Üí 0
    day_diff = day_diff.fillna(0)

    # negat√≠v √©rt√©kek ‚Üí 0
    day_diff = day_diff.clip(lower=0)

    return day_diff.astype(int)

def elozo_kesedelmes_szamlak_szama(
    df,
    customer_id_col,
    order_date_col,
    due_in_date_col,
    clear_date_col,
    x,
    y
):
    """
    √úgyfelenk√©nt kisz√°molja, hogy az aktu√°lis sz√°ml√°t megel≈ëz≈ë
    x darab sz√°mla k√∂z√ºl:
    - h√°ny volt legal√°bb y nap k√©sedelmes
    - h√°ny el≈ëz≈ë sz√°mla l√©tezett √∂sszesen
    """

    df = df.copy()

    # Id≈ërendi rendez√©s √ºgyfelenk√©nt
    df = df.sort_values([customer_id_col, order_date_col])

    # K√©sedelem sz√°m√≠t√°sa (kanonikus f√ºggv√©ny)
    df["_kesedelem_nap"] = kesedelmes_napok(
        df[due_in_date_col],
        df[clear_date_col]
    )

    # k√©sedelmes-e (bool)
    df["_kesedelmes"] = df["_kesedelem_nap"] >= y

    # 1Ô∏è‚É£ El≈ëz≈ë k√©sedelmes sz√°ml√°k sz√°ma
    elozo_kesedelmes_db = (
        df
        .groupby(customer_id_col)["_kesedelmes"]
        .apply(
            lambda s: (
                s.shift(1)
                 .rolling(window=x, min_periods=1)
                 .sum()
            )
        )
        .reset_index(level=0, drop=True)   # üîë KRITIKUS SOR
        .fillna(0)
        .astype(int)
    )

    # 2Ô∏è‚É£ El≈ëz≈ë sz√°ml√°k sz√°ma √∂sszesen
    elozo_szamlak_db = (
        df
        .groupby(customer_id_col)
        .cumcount()
        .clip(upper=x)
        .astype(int)
    )

    return elozo_kesedelmes_db, elozo_szamlak_db

